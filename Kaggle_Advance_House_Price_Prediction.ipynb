{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Kaggle Advance House Price Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHI1lD3WAX2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import datetime\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdnG3tclb1fc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/content/houseprice.csv\",usecols=[\"SalePrice\", \"MSSubClass\", \"MSZoning\", \"LotFrontage\", \"LotArea\",\n",
        "                                         \"Street\", \"YearBuilt\", \"LotShape\", \"1stFlrSF\", \"2ndFlrSF\"]).dropna()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsxOGhKBcC2z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "f047c5d3-7c6e-49bc-a001-49bc8c68b032"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>2003</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>1976</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>IR1</td>\n",
              "      <td>2001</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>IR1</td>\n",
              "      <td>1915</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>IR1</td>\n",
              "      <td>2000</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   MSSubClass MSZoning  LotFrontage  ...  1stFlrSF 2ndFlrSF SalePrice\n",
              "0          60       RL         65.0  ...       856      854    208500\n",
              "1          20       RL         80.0  ...      1262        0    181500\n",
              "2          60       RL         68.0  ...       920      866    223500\n",
              "3          70       RL         60.0  ...       961      756    140000\n",
              "4          60       RL         84.0  ...      1145     1053    250000\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STwzQUqwcFB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Total years'] = datetime.datetime.now().year-df['YearBuilt']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3Z56ADmdIvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop('YearBuilt',axis=1,inplace = True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py9uhyl7dN7C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "fa3909c1-2bbf-450f-ab60-3bbf4b713ea6"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>SalePrice</th>\n",
              "      <th>Total years</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>208500</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>181500</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>IR1</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>223500</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>IR1</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>140000</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>IR1</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>250000</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   MSSubClass MSZoning  LotFrontage  ...  2ndFlrSF SalePrice Total years\n",
              "0          60       RL         65.0  ...       854    208500          17\n",
              "1          20       RL         80.0  ...         0    181500          44\n",
              "2          60       RL         68.0  ...       866    223500          19\n",
              "3          70       RL         60.0  ...       756    140000         105\n",
              "4          60       RL         84.0  ...      1053    250000          20\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dkeoTOVdPSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_features=[\"MSSubClass\", \"MSZoning\", \"Street\", \"LotShape\"]\n",
        "out_feature=\"SalePrice\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iEN0gWbdxgO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "2d350519-fd8b-4fc1-8160-3b44de9865f8"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder =  {}\n",
        "encoder['MSSubClass'] = LabelEncoder()\n",
        "encoder['MSSubClass'].fit_transform(df['MSSubClass'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 5, ..., 6, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Aihbz_UeGzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = {}\n",
        "for feature in cat_features:\n",
        "  encoder[feature] = LabelEncoder()\n",
        "  df[feature] = encoder[feature].fit_transform(df[feature])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgdVwN9nfFFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVDgSKx-fLBR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "04ca6f04-3e89-449b-a117-223a03412dbc"
      },
      "source": [
        "cat_features = np.stack([df['MSSubClass'],df['MSZoning'],df['Street'],df['LotShape']],1)\n",
        "cat_features"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5, 3, 1, 3],\n",
              "       [0, 3, 1, 3],\n",
              "       [5, 3, 1, 0],\n",
              "       ...,\n",
              "       [6, 3, 1, 3],\n",
              "       [0, 3, 1, 3],\n",
              "       [0, 3, 1, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mklX1HuagKjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "2d3dfb75-b464-405e-88b7-62185f1d592c"
      },
      "source": [
        "import torch\n",
        "cat_features = torch.tensor(cat_features,dtype=torch.int64)\n",
        "cat_features"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5, 3, 1, 3],\n",
              "        [0, 3, 1, 3],\n",
              "        [5, 3, 1, 0],\n",
              "        ...,\n",
              "        [6, 3, 1, 3],\n",
              "        [0, 3, 1, 3],\n",
              "        [0, 3, 1, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAkz5zoRkYcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cont_features = []\n",
        "for i in df.columns:\n",
        "  if i in ['MSSubClass','MSZoning','Street','LotShape','SalePrice']:\n",
        "    pass\n",
        "  else:\n",
        "    cont_features.append(i)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-58OmEJmk4Oe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "9761e62a-7082-4cbf-945e-108a66a8e471"
      },
      "source": [
        "cont_features"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['LotFrontage', 'LotArea', '1stFlrSF', '2ndFlrSF', 'Total years']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkxnZm5yk-4T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "61dac522-637d-4612-c137-666554a24e5a"
      },
      "source": [
        "cont_values = np.stack([df[i].values for i in cont_features],axis=1)\n",
        "cont_values = torch.tensor(cont_values,dtype=torch.float)\n",
        "cont_values"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   65.,  8450.,   856.,   854.,    17.],\n",
              "        [   80.,  9600.,  1262.,     0.,    44.],\n",
              "        [   68., 11250.,   920.,   866.,    19.],\n",
              "        ...,\n",
              "        [   66.,  9042.,  1188.,  1152.,    79.],\n",
              "        [   68.,  9717.,  1078.,     0.,    70.],\n",
              "        [   75.,  9937.,  1256.,     0.,    55.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWn6TJWTlmQ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "9999f450-436a-45bb-df1c-152ba6d1b376"
      },
      "source": [
        "y = torch.tensor(df['SalePrice'].values,dtype=torch.float).reshape(-1,1)\n",
        "y"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[208500.],\n",
              "        [181500.],\n",
              "        [223500.],\n",
              "        ...,\n",
              "        [266500.],\n",
              "        [142125.],\n",
              "        [147500.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV6w4MocnUpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_dims = [len(df[col].unique()) for col in ['MSSubClass','MSZoning','Street','LotShape']]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VoGPCHuvP3x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "64b18925-c404-4f67-fbf9-7b63f3492777"
      },
      "source": [
        "cat_dims"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[15, 5, 2, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIzZNutBvQ34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = [(x,min(50,(x+1)//2)) for x in cat_dims]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK5wzbznvv6g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "5b995ae9-ae8f-4e47-89a6-15eef36f0f3d"
      },
      "source": [
        "embedding_dim"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(15, 8), (5, 3), (2, 1), (4, 2)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrCnsT0gvxGV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "eb5409b6-d24b-4a56-9968-a328a27403b4"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "embed_representation=nn.ModuleList([nn.Embedding(inp,out) for inp,out in embedding_dim])\n",
        "embed_representation"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModuleList(\n",
              "  (0): Embedding(15, 8)\n",
              "  (1): Embedding(5, 3)\n",
              "  (2): Embedding(2, 1)\n",
              "  (3): Embedding(4, 2)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rk_1FEWCH5Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "065b1de0-138b-4348-dccd-4ee522f29a22"
      },
      "source": [
        "cat_featurers  = cat_feat[:4]\n",
        "cat_featurers"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5, 3, 1, 3],\n",
              "        [0, 3, 1, 3],\n",
              "        [5, 3, 1, 0],\n",
              "        [6, 3, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbIe325XxJrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_rows',500)\n",
        "embedding_val = []\n",
        "for i,e in enumerate(embed_representation):\n",
        "  embedding_val.append(e(cat_features[:,i]))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MONoGvxkCy64",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "48c79fbb-7954-4477-8617-a865f81baae9"
      },
      "source": [
        "embedding_val"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[ 1.3084,  0.5572,  0.3316,  ...,  0.3779,  0.4534,  0.9133],\n",
              "         [ 0.8084, -0.6820,  1.1680,  ..., -0.0459,  0.7412,  0.1600],\n",
              "         [ 1.3084,  0.5572,  0.3316,  ...,  0.3779,  0.4534,  0.9133],\n",
              "         ...,\n",
              "         [ 0.2987, -0.6146,  0.4999,  ...,  0.4067,  0.4051, -0.4147],\n",
              "         [ 0.8084, -0.6820,  1.1680,  ..., -0.0459,  0.7412,  0.1600],\n",
              "         [ 0.8084, -0.6820,  1.1680,  ..., -0.0459,  0.7412,  0.1600]],\n",
              "        grad_fn=<EmbeddingBackward>), tensor([[ 1.6386, -0.5319,  2.3992],\n",
              "         [ 1.6386, -0.5319,  2.3992],\n",
              "         [ 1.6386, -0.5319,  2.3992],\n",
              "         ...,\n",
              "         [ 1.6386, -0.5319,  2.3992],\n",
              "         [ 1.6386, -0.5319,  2.3992],\n",
              "         [ 1.6386, -0.5319,  2.3992]], grad_fn=<EmbeddingBackward>), tensor([[-0.2293],\n",
              "         [-0.2293],\n",
              "         [-0.2293],\n",
              "         ...,\n",
              "         [-0.2293],\n",
              "         [-0.2293],\n",
              "         [-0.2293]], grad_fn=<EmbeddingBackward>), tensor([[-0.6975,  0.8154],\n",
              "         [-0.6975,  0.8154],\n",
              "         [-1.2093,  0.1298],\n",
              "         ...,\n",
              "         [-0.6975,  0.8154],\n",
              "         [-0.6975,  0.8154],\n",
              "         [-0.6975,  0.8154]], grad_fn=<EmbeddingBackward>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_ajQ-4DC03x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "f90d4ce8-6e25-4d0f-deed-d564c2ab4ef6"
      },
      "source": [
        "z = torch.cat(embedding_val,1)\n",
        "z"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.3084,  0.5572,  0.3316,  ..., -0.2293, -0.6975,  0.8154],\n",
              "        [ 0.8084, -0.6820,  1.1680,  ..., -0.2293, -0.6975,  0.8154],\n",
              "        [ 1.3084,  0.5572,  0.3316,  ..., -0.2293, -1.2093,  0.1298],\n",
              "        ...,\n",
              "        [ 0.2987, -0.6146,  0.4999,  ..., -0.2293, -0.6975,  0.8154],\n",
              "        [ 0.8084, -0.6820,  1.1680,  ..., -0.2293, -0.6975,  0.8154],\n",
              "        [ 0.8084, -0.6820,  1.1680,  ..., -0.2293, -0.6975,  0.8154]],\n",
              "       grad_fn=<CatBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVVGpG8UDI9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout = nn.Dropout(0.4)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlXeY9uWDQWm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "06354c85-43c3-491c-f0c0-bffeec5ddf3e"
      },
      "source": [
        "final_embed = dropout(z)\n",
        "final_embed"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.1806,  0.9287,  0.5526,  ..., -0.0000, -0.0000,  0.0000],\n",
              "        [ 1.3473, -0.0000,  0.0000,  ..., -0.0000, -1.1625,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.5526,  ..., -0.0000, -2.0155,  0.2164],\n",
              "        ...,\n",
              "        [ 0.0000, -0.0000,  0.0000,  ..., -0.3822, -1.1625,  0.0000],\n",
              "        [ 0.0000, -1.1366,  0.0000,  ..., -0.0000, -1.1625,  1.3591],\n",
              "        [ 1.3473, -1.1366,  1.9466,  ..., -0.0000, -1.1625,  1.3591]],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIMnAHpaDUjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class FeedForwardNN(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, n_cont, out_sz, layers, p=0.5):\n",
        "        super().__init__()\n",
        "        self.embeds = nn.ModuleList([nn.Embedding(inp,out) for inp,out in embedding_dim])\n",
        "        self.emb_drop = nn.Dropout(p)\n",
        "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
        "        \n",
        "        layerlist = []\n",
        "        n_emb = sum((out for inp,out in embedding_dim))\n",
        "        n_in = n_emb + n_cont\n",
        "        \n",
        "        for i in layers:\n",
        "            layerlist.append(nn.Linear(n_in,i)) \n",
        "            layerlist.append(nn.ReLU(inplace=True))\n",
        "            layerlist.append(nn.BatchNorm1d(i))\n",
        "            layerlist.append(nn.Dropout(p))\n",
        "            n_in = i\n",
        "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
        "            \n",
        "        self.layers = nn.Sequential(*layerlist)\n",
        "    \n",
        "    def forward(self, x_cat, x_cont):\n",
        "        embeddings = []\n",
        "        for i,e in enumerate(self.embeds):\n",
        "            embeddings.append(e(x_cat[:,i]))\n",
        "        x = torch.cat(embeddings, 1)\n",
        "        x = self.emb_drop(x)\n",
        "        \n",
        "        x_cont = self.bn_cont(x_cont)\n",
        "        x = torch.cat([x, x_cont], 1)\n",
        "        x = self.layers(x)\n",
        "        return x"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELU_S4B6HUk8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "342e8176-9592-456d-9375-0f287635acda"
      },
      "source": [
        "len(cont_features)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em06zyCjHYdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(100)\n",
        "model = FeedForwardNN(embedding_dim,len(cont_features),1,[100,50],p=0.2)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u7rHjfAJ0fO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "dc5d1fa1-988a-4085-cb7e-c6e17cb4856e"
      },
      "source": [
        "model"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FeedForwardNN(\n",
              "  (embeds): ModuleList(\n",
              "    (0): Embedding(15, 8)\n",
              "    (1): Embedding(5, 3)\n",
              "    (2): Embedding(2, 1)\n",
              "    (3): Embedding(4, 2)\n",
              "  )\n",
              "  (emb_drop): Dropout(p=0.2, inplace=False)\n",
              "  (bn_cont): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layers): Sequential(\n",
              "    (0): Linear(in_features=19, out_features=100, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.2, inplace=False)\n",
              "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): Dropout(p=0.2, inplace=False)\n",
              "    (8): Linear(in_features=50, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80ZvFwMzKEjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLbQsJHOKPZA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "556612d8-49cc-4efb-892a-8b321d2b750e"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1201, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNgrgguSKQKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1200\n",
        "test_size=int(batch_size*0.15)\n",
        "train_categorical=cat_features[:batch_size-test_size]\n",
        "test_categorical=cat_features[batch_size-test_size:batch_size]\n",
        "train_cont=cont_values[:batch_size-test_size]\n",
        "test_cont=cont_values[batch_size-test_size:batch_size]\n",
        "y_train=y[:batch_size-test_size]\n",
        "y_test=y[batch_size-test_size:batch_size]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70z1By_7L4Uf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94b4cd15-1951-4588-9f1a-ea978363bb9e"
      },
      "source": [
        "epochs=5000\n",
        "final_losses=[]\n",
        "for i in range(epochs):\n",
        "    i=i+1\n",
        "    y_pred=model(train_categorical,train_cont)\n",
        "    loss=torch.sqrt(loss_func(y_pred,y_train))\n",
        "    final_losses.append(loss)\n",
        "    if i%10==1:\n",
        "        print(\"Epoch number: {} and the loss : {}\".format(i,loss.item()))\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch number: 1 and the loss : 200496.796875\n",
            "Epoch number: 11 and the loss : 200493.34375\n",
            "Epoch number: 21 and the loss : 200488.71875\n",
            "Epoch number: 31 and the loss : 200482.21875\n",
            "Epoch number: 41 and the loss : 200473.125\n",
            "Epoch number: 51 and the loss : 200461.265625\n",
            "Epoch number: 61 and the loss : 200445.890625\n",
            "Epoch number: 71 and the loss : 200427.8125\n",
            "Epoch number: 81 and the loss : 200406.796875\n",
            "Epoch number: 91 and the loss : 200380.828125\n",
            "Epoch number: 101 and the loss : 200352.421875\n",
            "Epoch number: 111 and the loss : 200322.28125\n",
            "Epoch number: 121 and the loss : 200287.265625\n",
            "Epoch number: 131 and the loss : 200247.078125\n",
            "Epoch number: 141 and the loss : 200200.421875\n",
            "Epoch number: 151 and the loss : 200155.703125\n",
            "Epoch number: 161 and the loss : 200107.40625\n",
            "Epoch number: 171 and the loss : 200060.109375\n",
            "Epoch number: 181 and the loss : 199994.078125\n",
            "Epoch number: 191 and the loss : 199939.40625\n",
            "Epoch number: 201 and the loss : 199875.90625\n",
            "Epoch number: 211 and the loss : 199808.453125\n",
            "Epoch number: 221 and the loss : 199736.515625\n",
            "Epoch number: 231 and the loss : 199657.109375\n",
            "Epoch number: 241 and the loss : 199582.484375\n",
            "Epoch number: 251 and the loss : 199501.859375\n",
            "Epoch number: 261 and the loss : 199407.453125\n",
            "Epoch number: 271 and the loss : 199322.28125\n",
            "Epoch number: 281 and the loss : 199237.28125\n",
            "Epoch number: 291 and the loss : 199130.265625\n",
            "Epoch number: 301 and the loss : 199043.25\n",
            "Epoch number: 311 and the loss : 198933.875\n",
            "Epoch number: 321 and the loss : 198813.640625\n",
            "Epoch number: 331 and the loss : 198716.703125\n",
            "Epoch number: 341 and the loss : 198613.3125\n",
            "Epoch number: 351 and the loss : 198484.703125\n",
            "Epoch number: 361 and the loss : 198368.890625\n",
            "Epoch number: 371 and the loss : 198246.46875\n",
            "Epoch number: 381 and the loss : 198122.515625\n",
            "Epoch number: 391 and the loss : 197988.765625\n",
            "Epoch number: 401 and the loss : 197844.9375\n",
            "Epoch number: 411 and the loss : 197720.71875\n",
            "Epoch number: 421 and the loss : 197548.953125\n",
            "Epoch number: 431 and the loss : 197400.71875\n",
            "Epoch number: 441 and the loss : 197289.65625\n",
            "Epoch number: 451 and the loss : 197148.859375\n",
            "Epoch number: 461 and the loss : 196967.0625\n",
            "Epoch number: 471 and the loss : 196831.984375\n",
            "Epoch number: 481 and the loss : 196658.375\n",
            "Epoch number: 491 and the loss : 196512.609375\n",
            "Epoch number: 501 and the loss : 196337.328125\n",
            "Epoch number: 511 and the loss : 196154.453125\n",
            "Epoch number: 521 and the loss : 195990.53125\n",
            "Epoch number: 531 and the loss : 195817.765625\n",
            "Epoch number: 541 and the loss : 195622.890625\n",
            "Epoch number: 551 and the loss : 195439.125\n",
            "Epoch number: 561 and the loss : 195264.171875\n",
            "Epoch number: 571 and the loss : 195095.703125\n",
            "Epoch number: 581 and the loss : 194845.46875\n",
            "Epoch number: 591 and the loss : 194704.078125\n",
            "Epoch number: 601 and the loss : 194488.4375\n",
            "Epoch number: 611 and the loss : 194278.84375\n",
            "Epoch number: 621 and the loss : 194077.671875\n",
            "Epoch number: 631 and the loss : 193824.5\n",
            "Epoch number: 641 and the loss : 193658.5625\n",
            "Epoch number: 651 and the loss : 193481.796875\n",
            "Epoch number: 661 and the loss : 193241.65625\n",
            "Epoch number: 671 and the loss : 193019.78125\n",
            "Epoch number: 681 and the loss : 192781.796875\n",
            "Epoch number: 691 and the loss : 192591.203125\n",
            "Epoch number: 701 and the loss : 192342.921875\n",
            "Epoch number: 711 and the loss : 192149.546875\n",
            "Epoch number: 721 and the loss : 191839.828125\n",
            "Epoch number: 731 and the loss : 191601.984375\n",
            "Epoch number: 741 and the loss : 191403.96875\n",
            "Epoch number: 751 and the loss : 191168.796875\n",
            "Epoch number: 761 and the loss : 190956.53125\n",
            "Epoch number: 771 and the loss : 190665.265625\n",
            "Epoch number: 781 and the loss : 190538.078125\n",
            "Epoch number: 791 and the loss : 190148.421875\n",
            "Epoch number: 801 and the loss : 189920.171875\n",
            "Epoch number: 811 and the loss : 189615.546875\n",
            "Epoch number: 821 and the loss : 189466.25\n",
            "Epoch number: 831 and the loss : 189024.59375\n",
            "Epoch number: 841 and the loss : 188890.421875\n",
            "Epoch number: 851 and the loss : 188597.3125\n",
            "Epoch number: 861 and the loss : 188375.28125\n",
            "Epoch number: 871 and the loss : 188022.875\n",
            "Epoch number: 881 and the loss : 187746.6875\n",
            "Epoch number: 891 and the loss : 187531.359375\n",
            "Epoch number: 901 and the loss : 187196.375\n",
            "Epoch number: 911 and the loss : 186987.703125\n",
            "Epoch number: 921 and the loss : 186664.265625\n",
            "Epoch number: 931 and the loss : 186411.125\n",
            "Epoch number: 941 and the loss : 186101.53125\n",
            "Epoch number: 951 and the loss : 185830.25\n",
            "Epoch number: 961 and the loss : 185442.890625\n",
            "Epoch number: 971 and the loss : 185123.1875\n",
            "Epoch number: 981 and the loss : 184997.21875\n",
            "Epoch number: 991 and the loss : 184458.4375\n",
            "Epoch number: 1001 and the loss : 184403.765625\n",
            "Epoch number: 1011 and the loss : 183862.609375\n",
            "Epoch number: 1021 and the loss : 183639.8125\n",
            "Epoch number: 1031 and the loss : 183154.3125\n",
            "Epoch number: 1041 and the loss : 182999.03125\n",
            "Epoch number: 1051 and the loss : 182748.578125\n",
            "Epoch number: 1061 and the loss : 182337.71875\n",
            "Epoch number: 1071 and the loss : 182039.96875\n",
            "Epoch number: 1081 and the loss : 181941.4375\n",
            "Epoch number: 1091 and the loss : 181487.234375\n",
            "Epoch number: 1101 and the loss : 181163.359375\n",
            "Epoch number: 1111 and the loss : 180746.1875\n",
            "Epoch number: 1121 and the loss : 180517.328125\n",
            "Epoch number: 1131 and the loss : 180058.046875\n",
            "Epoch number: 1141 and the loss : 179611.8125\n",
            "Epoch number: 1151 and the loss : 179478.4375\n",
            "Epoch number: 1161 and the loss : 179026.703125\n",
            "Epoch number: 1171 and the loss : 178662.703125\n",
            "Epoch number: 1181 and the loss : 178322.96875\n",
            "Epoch number: 1191 and the loss : 177826.546875\n",
            "Epoch number: 1201 and the loss : 177655.390625\n",
            "Epoch number: 1211 and the loss : 177311.546875\n",
            "Epoch number: 1221 and the loss : 176963.515625\n",
            "Epoch number: 1231 and the loss : 176492.03125\n",
            "Epoch number: 1241 and the loss : 176007.5\n",
            "Epoch number: 1251 and the loss : 175763.265625\n",
            "Epoch number: 1261 and the loss : 175645.703125\n",
            "Epoch number: 1271 and the loss : 175122.5625\n",
            "Epoch number: 1281 and the loss : 174761.46875\n",
            "Epoch number: 1291 and the loss : 174570.8125\n",
            "Epoch number: 1301 and the loss : 173899.953125\n",
            "Epoch number: 1311 and the loss : 173741.84375\n",
            "Epoch number: 1321 and the loss : 173216.40625\n",
            "Epoch number: 1331 and the loss : 172835.46875\n",
            "Epoch number: 1341 and the loss : 172401.921875\n",
            "Epoch number: 1351 and the loss : 171973.4375\n",
            "Epoch number: 1361 and the loss : 171658.71875\n",
            "Epoch number: 1371 and the loss : 171178.9375\n",
            "Epoch number: 1381 and the loss : 171156.34375\n",
            "Epoch number: 1391 and the loss : 170632.75\n",
            "Epoch number: 1401 and the loss : 170019.1875\n",
            "Epoch number: 1411 and the loss : 169579.0\n",
            "Epoch number: 1421 and the loss : 169296.015625\n",
            "Epoch number: 1431 and the loss : 168966.890625\n",
            "Epoch number: 1441 and the loss : 168664.625\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}